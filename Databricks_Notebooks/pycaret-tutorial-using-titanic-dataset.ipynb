{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pip install PyCaret","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip3 install pycaret","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading the Required Packages","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom pycaret import classification","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Getting the Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/titanic/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Setting up Environment","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_setup = classification.setup(data=train,target='Survived')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Once the setup has been succesfully executed it prints the information grid which contains several important pieces of information. Most of the information is related to the pre-processing pipeline which is constructed when setup() is executed.*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Compare Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"classification.compare_models()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Note** : *Comparing all models to evaluate performance is the recommended starting point for modeling once the setup is completed (unless you exactly know what kind of model you need, which is often not the case). This function trains all models in the model library and scores them using kfold cross validation for metric evaluation.* ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create Xgboost model\nclassification_xgb = classification.create_model('xgboost')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*The output prints a score grid that shows average Accuracy, AUC, Recall, Precision, F1, Kappa accross the folds (10 by default) of all the available models in the model library.*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tune the model\ntune_xgb = classification.tune_model('xgboost')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Obeserve the difference when the model is run with default parameters and after fine tuning them*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# build the lightgbm model\nclassification_lightgbm = classification.create_model('lightgbm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tune lightgbm model\ntune_lightgbm = classification.tune_model('lightgbm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plot Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Residual Plot\nclassification.plot_model(tune_lightgbm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Error Plot\nclassification.plot_model(tune_lightgbm, plot = 'error')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Important plot\nclassification.plot_model(tune_lightgbm, plot='feature')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate model\nclassification.evaluate_model(tune_lightgbm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Make Predictions - Xgboost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# read the test data\ntest_data_classification = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n# make predictions\npredictions = classification.predict_model(tune_xgb, data=test_data_classification)\n# view the predictions\npredictions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2 .Make Predictions - lightgbm","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# read the test data\ntest_data_classification = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n# make predictions\npredictions = classification.predict_model(tune_lightgbm, data=test_data_classification)\n# view the predictions\npredictions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Thanks for reading.If you like it Kindly Upvote","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Special Thanks to : **Moez Ali** - Data Scientist, Founder & Author of PyCaret & **Analytics Vidhya**\n\n[https://towardsdatascience.com/announcing-pycaret-an-open-source-low-code-machine-learning-library-in-python-4a1f1aad8d46](http://)\n\n[https://www.analyticsvidhya.com/blog/2020/05/pycaret-machine-learning-model-seconds/?utm_source=feed&utm_medium=feed-articles&utm_campaign=feed](http://)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}